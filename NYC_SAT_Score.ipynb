{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Importing some of the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### Reading the datasets\n",
    "location='/Users/chaitanya/Data_science/datasets_NYC/'\n",
    "files = [\"ap_2010.csv\", \"class_size.csv\", \"demographics.csv\", \\\n",
    " \"graduation.csv\", \"hs_directory.csv\", \"math_test_results.csv\", \"sat_results.csv\"]\n",
    "###### Creating an empty dictionary to store the dataset\n",
    "data={}\n",
    "for f in range(len(files)):\n",
    "    d=pd.read_csv(''.join([location,files[f]]))\n",
    "    data[files[f].replace(\".csv\", \"\")] = d\n",
    "    key_data=data.keys()\n",
    "### Visualise the data sets\n",
    "#for i in range(len(key_data)):\n",
    "#    print (\"\\n\")\n",
    "#    print (key_data[i])\n",
    "#    print (\"\\n\")\n",
    "#    print (data.values()[i].head(3))\n",
    "print \"+++++++++++++++++++++++++++++++++++\"\n",
    "#print key_data\n",
    "#for index in range(len(key_data)):\n",
    "#    print key_data[index]\n",
    "#    print (\"\\n\")\n",
    "#    print data[key_data[index]].columns\n",
    "#    print (\"\\n\")\n",
    "    \n",
    "### Renaming the dbn column in hs_directory dataframe\n",
    "#print data['hs_directory']['dbn'].head()\n",
    "data['hs_directory'].rename(columns={'dbn':'DBN'},inplace=True)\n",
    "#print data['hs_directory'].columns\n",
    "#print data['hs_directory']['DBN'].head()\n",
    "data[\"class_size\"][\"DBN\"] = data[\"class_size\"].apply(lambda x: \"{0:02d}{1}\".format(x[\"CSD\"],x[\"SCHOOL CODE\"]), axis=1)\n",
    "data[\"class_size\"][\"DBN\"]\n",
    "data['class_size'].rename(columns={'GRADE ':'GRADE'},inplace=True)\n",
    "#del data['hs_directory']['dbn']\n",
    "#data['hs_directory']=data['hs_directory'].rename(columns({'dbn':'DBN'})\n",
    "#data['hs_directory']['DBN']=data['hs_directory']['dbn']\n",
    "#print data['hs_directory']['DBN'].head()\n",
    "\n",
    "\n",
    "\n",
    "### Survey dataset\n",
    "\n",
    "survey_75 = pd.read_csv(''.join([location,'masterfile11_d75_final.txt']), delimiter=\"\\t\", encoding='windows-1252')\n",
    "survey_not75 = pd.read_csv(''.join([location,'masterfile11_gened_final.txt']), delimiter=\"\\t\", encoding='windows-1252')\n",
    "survey_75['flag75']=True\n",
    "survey_not75['flag75']=False\n",
    "survey=pd.concat([survey_75,survey_not75],axis=0)\n",
    "#survey.head()\n",
    "# Removing extraneuous columns from the dataset\n",
    "\n",
    "survey.rename(columns={'dbn':'DBN'},inplace=True)\n",
    "survey_fields = [\"DBN\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \\\n",
    "                 \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\",\\\n",
    "                 \"com_t_11\", \"eng_t_10\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \\\n",
    "                 \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "survey = survey.loc[:,survey_fields]\n",
    "print survey.info()\n",
    "data['survey']=survey \n",
    "#### Collecting relevant data \n",
    "#### Removing unnecessary columns from the dataset\n",
    "grade_flag=data[\"class_size\"]['GRADE']=='09-12'\n",
    "prgm_flag=data[\"class_size\"]['PROGRAM TYPE']=='GEN ED'\n",
    "data[\"class_size\"]= data[\"class_size\"][grade_flag & prgm_flag]\n",
    "class_size= data[\"class_size\"].groupby(data[\"class_size\"]['DBN']).mean()\n",
    "class_size.reset_index(inplace=True)\n",
    "data[\"class_size\"]=class_size\n",
    "\n",
    "\n",
    "\n",
    "#### Collecting relevant data  from the demographics dataset\n",
    "\n",
    "#print data[\"demographics\"].head()\n",
    "recent_sch_year=data[\"demographics\"].sort_values('schoolyear',ascending=False)['schoolyear'].head(1).values[0]\n",
    "demograph_data= data[\"demographics\"][data[\"demographics\"]['schoolyear']==recent_sch_year]\n",
    "data[\"demographics\"]=demograph_data\n",
    "mathsdata=data[\"math_test_results\"]\n",
    "#print mathsdata.Year\n",
    "gradeflag=mathsdata.Grade=='8'\n",
    "yearflag=mathsdata.Year==2011\n",
    "mathsdata=mathsdata[yearflag & gradeflag]\n",
    "data[\"math_test_results\"]=mathsdata\n",
    "#data[\"math_test_results\"].head()\n",
    "\n",
    "\n",
    "#### Collecting relevant data  from the graduation dataset\n",
    "data[\"graduation\"]=data[\"graduation\"][data[\"graduation\"]['Cohort']=='2006']\n",
    "data[\"graduation\"]=data[\"graduation\"][data[\"graduation\"]['Demographic']=='Total Cohort']\n",
    "#data[\"graduation\"].head()\n",
    "\n",
    "#### Calculating the total sat score \n",
    "cols = ['SAT Math Avg. Score', 'SAT Critical Reading Avg. Score', 'SAT Writing Avg. Score']\n",
    "for c in cols:\n",
    "    data[\"sat_results\"][c] = pd.to_numeric(data[\"sat_results\"][c],errors='ignore')\n",
    "\n",
    "data['sat_results']['sat_score'] = data['sat_results'][cols[0]]\\\n",
    "+ data['sat_results'][cols[1]] + data['sat_results'][cols[2]]\n",
    "#data['sat_results']['sat_score'].head(15)\n",
    "\n",
    "#### Getting the location of each school \n",
    "data[\"hs_directory\"]['lat'] = data[\"hs_directory\"]['Location 1'].\\\n",
    "apply(lambda x: x.split(\"\\n\")[-1].replace(\"(\", \"\").replace(\")\", \"\").split(\", \")[0])\n",
    "data[\"hs_directory\"]['lon'] = data[\"hs_directory\"]['Location 1'].\\\n",
    "apply(lambda x: x.split(\"\\n\")[-1].replace(\"(\", \"\").replace(\")\", \"\").split(\", \")[1])\n",
    "for c in ['lat', 'lon']:\n",
    "    data[\"hs_directory\"][c] = pd.to_numeric(data[\"hs_directory\"][c],errors='ignore')\n",
    "#data[\"hs_directory\"].head()    \n",
    "\n",
    "##### The entire datasets\n",
    "\n",
    "\n",
    "print \"++++++++++++++++++++++++++++\"\n",
    "#for k,v in data.items():\n",
    "#    print(k)\n",
    "#    print\"/n\"\n",
    "#    print(v.head(4))\n",
    "\n",
    "\n",
    "data_names=data.keys()\n",
    "full_data=[data[data_names[v]] for v in range (len(data_names))]\n",
    "\n",
    "flat_data_names = [k for k,v in data.items()]\n",
    "flat_data = [data[k] for k in flat_data_names]\n",
    "full = flat_data[0]\n",
    "for i, f in enumerate(flat_data[1:]):\n",
    "    name = flat_data_names[i+1]\n",
    "    print(name)\n",
    "    print(len(f[\"DBN\"]) - len(f[\"DBN\"].unique()))\n",
    "    join_type = \"inner\"\n",
    "    if name in [\"sat_results\", \"ap_2010\", \"graduation\"]:\n",
    "        join_type = \"outer\"\n",
    "    if name not in [\"math_test_results\"]:\n",
    "        full = full.merge(f, on=\"DBN\", how=join_type)\n",
    "        \n",
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']   \n",
    "for col in cols:\n",
    "    full[col] = pd.to_numeric(full[col],errors='ignore')\n",
    "\n",
    "full[cols] = full[cols].fillna(value=0)\n",
    "full[\"school_dist\"] = full[\"DBN\"].apply(lambda x: x[:2])\n",
    "##### The full dataset\n",
    "full = full.fillna(full.mean())\n",
    "##### Computing the correlations \n",
    "full['sat_score']=full['sat_score'].replace('sss', np.nan)\n",
    "full=full.loc[full['sat_score'].notnull()]\n",
    "full['total_enrollment'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
